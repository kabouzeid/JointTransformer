from __future__ import print_function, unicode_literals

import base64

import open3d as o3d
from scipy.linalg import orthogonal_procrustes

from src.utils.utils.eval_util import EvalUtil
from src.utils.utils.fh_utils import *


def verts2pcd(verts, color=None):
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(verts)
    if color is not None:
        if color == "r":
            pcd.paint_uniform_color([1, 0.0, 0])
        if color == "g":
            pcd.paint_uniform_color([0, 1.0, 0])
        if color == "b":
            pcd.paint_uniform_color([0, 0, 1.0])
    return pcd


def calculate_fscore(gt, pr, th=0.01):
    gt = verts2pcd(gt)
    pr = verts2pcd(pr)
    d1 = gt.compute_point_cloud_distance(pr)  # closest dist for each gt point
    d2 = pr.compute_point_cloud_distance(pr)  # closest dist for each pred point
    if len(d1) and len(d2):
        recall = float(sum(d < th for d in d2)) / float(
            len(d2)
        )  # how many of our predicted points lie close to a gt point?
        precision = float(sum(d < th for d in d1)) / float(
            len(d1)
        )  # how many of gt points are matched?

        if recall + precision > 0:
            fscore = 2 * recall * precision / (recall + precision)
        else:
            fscore = 0
    else:
        fscore = 0
        precision = 0
        recall = 0
    return fscore, precision, recall


def align_w_scale(mtx1, mtx2, return_trafo=False):
    """Align the predicted entity in some optimality sense with the ground truth."""
    # center
    t1 = mtx1.mean(0)
    t2 = mtx2.mean(0)
    mtx1_t = mtx1 - t1
    mtx2_t = mtx2 - t2

    # scale
    s1 = np.linalg.norm(mtx1_t) + 1e-8
    mtx1_t /= s1
    s2 = np.linalg.norm(mtx2_t) + 1e-8
    mtx2_t /= s2

    # orth alignment
    R, s = orthogonal_procrustes(mtx1_t, mtx2_t)

    # apply trafos to the second matrix
    mtx2_t = np.dot(mtx2_t, R.T) * s
    mtx2_t = mtx2_t * s1 + t1
    if return_trafo:
        return R, s, s1, t1 - t2
    else:
        return mtx2_t


def align_by_trafo(mtx, trafo):
    t2 = mtx.mean(0)
    mtx_t = mtx - t2
    R, s, s1, t1 = trafo
    return np.dot(mtx_t, R.T) * s * s1 + t1 + t2


class curve:
    def __init__(self, x_data, y_data, x_label, y_label, text):
        self.x_data = x_data
        self.y_data = y_data
        self.x_label = x_label
        self.y_label = y_label
        self.text = text


def createHTML(outputDir, curve_list):
    curve_data_list = list()
    for item in curve_list:
        fig1 = plt.figure()
        ax = fig1.add_subplot(111)
        ax.plot(item.x_data, item.y_data)
        ax.set_xlabel(item.x_label)
        ax.set_ylabel(item.y_label)
        img_path = os.path.join(outputDir, "img_path_path.png")
        plt.savefig(img_path, bbox_inches=0, dpi=300)

        # write image and create html embedding
        with open(img_path, "rb") as file:
            data_uri1 = base64.b64encode(file.read()).decode("utf-8").replace("\n", "")

        img_tag1 = 'src="data:image/png;base64,{0}"'.format(data_uri1)
        curve_data_list.append((item.text, img_tag1))

        os.remove(img_path)

    htmlString = """<!DOCTYPE html>
    <html>
    <body>
    <h1>Detailed results:</h1>"""

    for i, (text, img_embed) in enumerate(curve_data_list):
        htmlString += """
        <h2>%s</h2>
        <p>
        <img border="0" %s alt="FROC" width="576pt" height="432pt">
        </p>
        <p>Raw curve data:</p>
        
        <p>x_axis: <small>%s</small></p>
        <p>y_axis: <small>%s</small></p>
        
        """ % (
            text,
            img_embed,
            curve_list[i].x_data,
            curve_list[i].y_data,
        )

    htmlString += """
    </body>
    </html>"""

    htmlfile = open(os.path.join(outputDir, "scores.html"), "w")
    htmlfile.write(htmlString)
    htmlfile.close()


def main(gt_path, pred_file_path, output_dir, set_name=None):
    if output_dir is None:
        output_dir = os.path.dirname(pred_file_path)
    if set_name is None:
        set_name = "evaluation"

    # load eval annotations
    xyz_list, verts_list = json_load(
        os.path.join(gt_path, "%s_xyz.json" % set_name)
    ), json_load(os.path.join(gt_path, "%s_verts.json" % set_name))

    # load predicted values
    print("Loading predictions from %s" % pred_file_path)
    with open(pred_file_path, "r") as fi:
        pred = json.load(fi)

    assert len(pred) == 2, "Expected format mismatch."
    assert len(pred[0]) == len(xyz_list), "Expected format mismatch."
    assert len(pred[1]) == len(xyz_list), "Expected format mismatch."

    # init eval utils
    eval_xyz, eval_xyz_aligned = EvalUtil(), EvalUtil()
    eval_mesh_err, eval_mesh_err_aligned = EvalUtil(num_kp=778), EvalUtil(num_kp=778)
    f_score, f_score_aligned = list(), list()
    f_threshs = [0.005, 0.015]

    shape_is_mano = None

    try:
        from tqdm import tqdm

        rng = tqdm(range(db_size(set_name)))
    except:
        rng = range(db_size(set_name))

    # iterate over the dataset once
    for idx in rng:
        if idx >= db_size(set_name):
            break

        xyz, verts = xyz_list[idx], verts_list[idx]
        xyz, verts = [np.array(x) for x in [xyz, verts]]

        xyz_pred, verts_pred = pred[0][idx], pred[1][idx]
        xyz_pred, verts_pred = [np.array(x) for x in [xyz_pred, verts_pred]]

        # Not aligned errors
        eval_xyz.feed(xyz, np.ones_like(xyz[:, 0]), xyz_pred)

        if shape_is_mano is None:
            if verts_pred.shape[0] == verts.shape[0]:
                shape_is_mano = True
            else:
                shape_is_mano = False

        if shape_is_mano:
            eval_mesh_err.feed(verts, np.ones_like(verts[:, 0]), verts_pred)

        # align predictions
        xyz_pred_aligned = align_w_scale(xyz, xyz_pred)
        if shape_is_mano:
            verts_pred_aligned = align_w_scale(verts, verts_pred)
        else:
            # use trafo estimated from keypoints
            trafo = align_w_scale(xyz, xyz_pred, return_trafo=True)
            verts_pred_aligned = align_by_trafo(verts_pred, trafo)

        # Aligned errors
        eval_xyz_aligned.feed(xyz, np.ones_like(xyz[:, 0]), xyz_pred_aligned)

        if shape_is_mano:
            eval_mesh_err_aligned.feed(
                verts, np.ones_like(verts[:, 0]), verts_pred_aligned
            )

        # F-scores
        l, la = list(), list()
        for t in f_threshs:
            # for each threshold calculate the f score and the f score of the aligned vertices
            f, _, _ = calculate_fscore(verts, verts_pred, t)
            l.append(f)
            f, _, _ = calculate_fscore(verts, verts_pred_aligned, t)
            la.append(f)
        f_score.append(l)
        f_score_aligned.append(la)

    # Calculate results
    xyz_mean3d, _, xyz_auc3d, pck_xyz, thresh_xyz = eval_xyz.get_measures(
        0.0, 0.05, 100
    )
    print("Evaluation 3D KP results:")
    print("auc=%.3f, mean_kp3d_avg=%.2f cm" % (xyz_auc3d, xyz_mean3d * 100.0))

    (
        xyz_al_mean3d,
        _,
        xyz_al_auc3d,
        pck_xyz_al,
        thresh_xyz_al,
    ) = eval_xyz_aligned.get_measures(0.0, 0.05, 100)
    print("Evaluation 3D KP ALIGNED results:")
    print("auc=%.3f, mean_kp3d_avg=%.2f cm\n" % (xyz_al_auc3d, xyz_al_mean3d * 100.0))

    if shape_is_mano:
        mesh_mean3d, _, mesh_auc3d, pck_mesh, thresh_mesh = eval_mesh_err.get_measures(
            0.0, 0.05, 100
        )
        print("Evaluation 3D MESH results:")
        print("auc=%.3f, mean_kp3d_avg=%.2f cm" % (mesh_auc3d, mesh_mean3d * 100.0))

        (
            mesh_al_mean3d,
            _,
            mesh_al_auc3d,
            pck_mesh_al,
            thresh_mesh_al,
        ) = eval_mesh_err_aligned.get_measures(0.0, 0.05, 100)
        print("Evaluation 3D MESH ALIGNED results:")
        print(
            "auc=%.3f, mean_kp3d_avg=%.2f cm\n"
            % (mesh_al_auc3d, mesh_al_mean3d * 100.0)
        )
    else:
        mesh_mean3d, mesh_auc3d, mesh_al_mean3d, mesh_al_auc3d = -1.0, -1.0, -1.0, -1.0

        pck_mesh, thresh_mesh = np.array([-1.0, -1.0]), np.array([0.0, 1.0])
        pck_mesh_al, thresh_mesh_al = np.array([-1.0, -1.0]), np.array([0.0, 1.0])

    print("F-scores")
    f_out = list()
    f_score, f_score_aligned = np.array(f_score).T, np.array(f_score_aligned).T
    for f, fa, t in zip(f_score, f_score_aligned, f_threshs):
        print(
            "F@%.1fmm = %.3f" % (t * 1000, f.mean()),
            "\tF_aligned@%.1fmm = %.3f" % (t * 1000, fa.mean()),
        )
        f_out.append("f_score_%d: %f" % (round(t * 1000), f.mean()))
        f_out.append("f_al_score_%d: %f" % (round(t * 1000), fa.mean()))

    # Dump results
    score_path = os.path.join(output_dir, "scores.txt")
    with open(score_path, "w") as fo:
        xyz_mean3d *= 100
        xyz_al_mean3d *= 100
        fo.write("xyz_mean3d: %f\n" % xyz_mean3d)
        fo.write("xyz_auc3d: %f\n" % xyz_auc3d)
        fo.write("xyz_al_mean3d: %f\n" % xyz_al_mean3d)
        fo.write("xyz_al_auc3d: %f\n" % xyz_al_auc3d)

        mesh_mean3d *= 100
        mesh_al_mean3d *= 100
        fo.write("mesh_mean3d: %f\n" % mesh_mean3d)
        fo.write("mesh_auc3d: %f\n" % mesh_auc3d)
        fo.write("mesh_al_mean3d: %f\n" % mesh_al_mean3d)
        fo.write("mesh_al_auc3d: %f\n" % mesh_al_auc3d)
        for t in f_out:
            fo.write("%s\n" % t)
    print("Scores written to: %s" % score_path)

    # scale to cm
    thresh_xyz *= 100.0
    thresh_xyz_al *= 100.0
    thresh_mesh *= 100.0
    thresh_mesh_al *= 100.0

    createHTML(
        output_dir,
        [
            curve(
                thresh_xyz,
                pck_xyz,
                "Distance in cm",
                "Percentage of correct keypoints",
                "PCK curve for keypoint error",
            ),
            curve(
                thresh_xyz_al,
                pck_xyz_al,
                "Distance in cm",
                "Percentage of correct keypoints",
                "PCK curve for aligned keypoint error",
            ),
            curve(
                thresh_mesh,
                pck_mesh,
                "Distance in cm",
                "Percentage of correct vertices",
                "PCV curve for mesh error",
            ),
            curve(
                thresh_mesh_al,
                pck_mesh_al,
                "Distance in cm",
                "Percentage of correct vertices",
                "PCV curve for aligned mesh error",
            ),
        ],
    )

    pck_curve_data = {
        "xyz": [thresh_xyz.tolist(), pck_xyz.tolist()],
        "xyz_al": [thresh_xyz_al.tolist(), pck_xyz_al.tolist()],
        "mesh": [thresh_mesh.tolist(), pck_mesh.tolist()],
        "mesh_al": [thresh_mesh_al.tolist(), pck_mesh_al.tolist()],
    }
    with open("pck_data.json", "w") as fo:
        json.dump(pck_curve_data, fo)

    print("Evaluation complete.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "data_dir",
        type=str,
    )
    parser.add_argument("pred_file", type=str)
    args = parser.parse_args()

    # call eval
    main(args.data_dir, args.pred_file, None, set_name="evaluation")


def eval_freihand_metrics(
    xyz_pred,
    verts_pred,
    gt_path="/globalwork/abou_zeid/datasets/FreiHAND_pub_v2_eval/",
    set_name="evaluation",
):
    # load eval annotations
    xyz_list, verts_list = json_load(
        os.path.join(gt_path, "%s_xyz.json" % set_name)
    ), json_load(os.path.join(gt_path, "%s_verts.json" % set_name))

    # load predicted values
    pred = [xyz_pred, verts_pred]

    assert len(pred) == 2, "Expected format mismatch."
    assert len(pred[0]) == len(xyz_list), "Expected format mismatch."
    assert len(pred[1]) == len(xyz_list), "Expected format mismatch."

    # init eval utils
    eval_xyz, eval_xyz_aligned = EvalUtil(), EvalUtil()
    eval_mesh_err, eval_mesh_err_aligned = EvalUtil(num_kp=778), EvalUtil(num_kp=778)
    f_score, f_score_aligned = list(), list()
    f_threshs = [0.005, 0.015]

    # iterate over the dataset once
    for idx in range(db_size(set_name)):
        if idx >= db_size(set_name):
            break

        xyz, verts = xyz_list[idx], verts_list[idx]
        xyz, verts = [np.array(x) for x in [xyz, verts]]

        xyz_pred, verts_pred = pred[0][idx], pred[1][idx]
        xyz_pred, verts_pred = [np.array(x) for x in [xyz_pred, verts_pred]]

        # Not aligned errors
        eval_xyz.feed(xyz, np.ones_like(xyz[:, 0]), xyz_pred)

        eval_mesh_err.feed(verts, np.ones_like(verts[:, 0]), verts_pred)

        # align predictions
        xyz_pred_aligned = align_w_scale(xyz, xyz_pred)
        verts_pred_aligned = align_w_scale(verts, verts_pred)

        # Aligned errors
        eval_xyz_aligned.feed(xyz, np.ones_like(xyz[:, 0]), xyz_pred_aligned)

        eval_mesh_err_aligned.feed(verts, np.ones_like(verts[:, 0]), verts_pred_aligned)

        # F-scores
        l, la = list(), list()
        for t in f_threshs:
            # for each threshold calculate the f score and the f score of the aligned vertices
            f, _, _ = calculate_fscore(verts, verts_pred, t)
            l.append(f)
            f, _, _ = calculate_fscore(verts, verts_pred_aligned, t)
            la.append(f)
        f_score.append(l)
        f_score_aligned.append(la)

    (
        xyz_al_mean3d,
        _,
        xyz_al_auc3d,
        pck_xyz_al,
        thresh_xyz_al,
    ) = eval_xyz_aligned.get_measures(0.0, 0.05, 100)

    (
        mesh_al_mean3d,
        _,
        mesh_al_auc3d,
        pck_mesh_al,
        thresh_mesh_al,
    ) = eval_mesh_err_aligned.get_measures(0.0, 0.05, 100)

    f_score, f_score_aligned = np.array(f_score).T, np.array(f_score_aligned).T

    xyz_al_mean3d *= 100
    mesh_al_mean3d *= 100

    out_dict = {
        "xyz_al_mean3d": xyz_al_mean3d,
        "xyz_al_auc3d": xyz_al_auc3d,
        "mesh_al_mean3d": mesh_al_mean3d,
        "mesh_al_auc3d": mesh_al_auc3d,
    }

    for fa, t in zip(f_score_aligned, f_threshs):
        out_dict[f"f_al_score_{round(t * 1000)}"] = fa.mean()

    return out_dict
